{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in /home/iiitd/.local/lib/python3.5/site-packages (6.4.0)\n",
      "Requirement already satisfied: update-checker>=0.16 in /home/iiitd/.local/lib/python3.5/site-packages (from praw) (0.16)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /home/iiitd/.local/lib/python3.5/site-packages (from praw) (0.56.0)\n",
      "Requirement already satisfied: prawcore<2.0,>=1.0.1 in /home/iiitd/.local/lib/python3.5/site-packages (from praw) (1.0.1)\n",
      "Requirement already satisfied: requests>=2.3.0 in /usr/lib/python3/dist-packages (from update-checker>=0.16->praw) (2.9.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from websocket-client>=0.54.0->praw) (1.10.0)\n",
      "Requirement already satisfied: numpy in /home/iiitd/.local/lib/python3.5/site-packages (1.16.1)\n",
      "Requirement already satisfied: pandas in /home/iiitd/.local/lib/python3.5/site-packages (0.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/iiitd/.local/lib/python3.5/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/iiitd/.local/lib/python3.5/site-packages (from pandas) (1.16.1)\n",
      "Requirement already satisfied: pytz>=2011k in /home/iiitd/.local/lib/python3.5/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.5.0->pandas) (1.10.0)\n",
      "Requirement already satisfied: lxml in /home/iiitd/.local/lib/python3.5/site-packages (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw --user\n",
    "!pip install numpy --user\n",
    "!pip install pandas --user\n",
    "!pip install lxml --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw \n",
    "from praw.models import MoreComments\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Submissions for each flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs_mapping = {'AskIndia':1,'Business/Finance':2,'Food':3,'Non-Political':4,'Photography':5,'Policy/Economy':6,'Politics':7,'Scheduled':8,'Science/Technology':9,'Sports':10}\n",
    "flairs = flairs_mapping.keys()\n",
    "reddit = praw.Reddit(client_id=\"z8UhRRiFnEVZ8Q\",\n",
    "                     client_secret=\"bV7OxwG-VKjdyKxcuUihnV1lNPg\",\n",
    "                     password=\"qazwsx123\",\n",
    "                     username=\"lshreyasharmal\",\n",
    "                     user_agent=\"bot1 user agent\")\n",
    "\n",
    "subreddit = reddit.subreddit(\"india\")\n",
    "submissions = {}\n",
    "for flair in flairs:\n",
    "    get_subreddits = subreddit.search(flair, limit=200)\n",
    "    for submission in get_subreddits:\n",
    "        if flair not in submissions.keys():\n",
    "            submissions[flair] = []\n",
    "        submissions[flair].append(submission)\n",
    "np.save(\"submissions.npy\",submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect post features from submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for flair_value,subs in submissions.items():\n",
    "    for submission in subs:\n",
    "        post = vars(submission)\n",
    "        submission.comments.replace_more(limit = None)\n",
    "        comments = \"\"\n",
    "        for comment in submission.comments:\n",
    "            comments += \" \" + comment.body\n",
    "        post[\"comments\"] = comments\n",
    "        author = str(submission.author).split(\"'\")\n",
    "        post['author'] = author[len(author)-2]\n",
    "        post['target'] = flairs_mapping[flair_value]\n",
    "        dataset.append(post)\n",
    "np.save(\"dataset.npy\",dataset)\n",
    "data = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns with same value accross all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = []\n",
    "for col in data.columns:\n",
    "    try:\n",
    "        if data[col].nunique()<2:\n",
    "            cols_to_drop.append(col)\n",
    "    except:\n",
    "        cols_to_drop.append(col)\n",
    "data = data.drop(cols_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Flair Type column from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['link_flair_text'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess different data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [col for col in data.columns if np.issubdtype(data[col].dtype, np.number)]\n",
    "\n",
    "boolean_cols = [col for col in data.columns if data[col].dtype == \"bool\"]\n",
    "\n",
    "object_cols = [col for col in data.columns if data[col].dtype == \"object\"]\n",
    "\n",
    "def preprocess_strings(x):\n",
    "    x = re.sub(r'http\\S+', '', x, flags=re.MULTILINE)\n",
    "    x = BeautifulSoup(x, \"html.parser\").text\n",
    "    x = x.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    x = re.sub(r'[^a-zA-z\\s]', '', x)\n",
    "    x = x.lower()\n",
    "    x = x.strip()\n",
    "    x = re.sub(r'\\W',\" \",x)\n",
    "    return x\n",
    "\n",
    "final_data = []\n",
    "\n",
    "for row in data.iterrows():\n",
    "    final_data_point = {}\n",
    "    for col in object_cols:\n",
    "        if isinstance(row[1][col],str):\n",
    "            final_data_point[col] = preprocess_strings(row[1][col])\n",
    "    for col in boolean_cols:\n",
    "        final_data_point[col] = 1 if row[1][col] else 0\n",
    "    for col in numerical_cols:\n",
    "        final_data_point[col] = row[1][col]\n",
    "    final_data.append(final_data_point)\n",
    "    \n",
    "final_dataframe = pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.to_csv(\"final_data.csv\",index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"string_cols.npy\",object_cols)\n",
    "np.save(\"numerical_cols.npy\",numerical_cols)\n",
    "np.save(\"boolean_cols.npy\",boolean_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['allow_live_comments', 'archived', 'author',\n",
       "       'author_flair_background_color', 'author_flair_css_class',\n",
       "       'author_flair_template_id', 'author_flair_text',\n",
       "       'author_flair_text_color', 'author_flair_type', 'author_fullname',\n",
       "       'author_premium', 'comments', 'contest_mode', 'created', 'created_utc',\n",
       "       'domain', 'gilded', 'hide_score', 'id', 'is_original_content',\n",
       "       'is_reddit_media_domain', 'is_self', 'is_video',\n",
       "       'link_flair_background_color', 'link_flair_css_class',\n",
       "       'link_flair_template_id', 'link_flair_text_color', 'link_flair_type',\n",
       "       'locked', 'name', 'no_follow', 'num_comments', 'num_crossposts',\n",
       "       'num_duplicates', 'permalink', 'post_hint', 'score', 'selftext',\n",
       "       'selftext_html', 'send_replies', 'spoiler', 'stickied',\n",
       "       'subreddit_subscribers', 'suggested_sort', 'target', 'thumbnail',\n",
       "       'thumbnail_height', 'thumbnail_width', 'title', 'total_awards_received',\n",
       "       'ups', 'upvote_ratio', 'url', 'whitelist_status', 'wls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
