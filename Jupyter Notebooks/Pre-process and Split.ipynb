{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from gensim.models import FastText\n",
    "from preprocessing_functions import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_data.npy\",\"rb\") as file:\n",
    "    data_ = np.load(file,encoding='bytes')\n",
    "\n",
    "keys = [x.decode(\"utf-8\")  for x in data_[0].keys()]\n",
    "keys\n",
    "\n",
    "np_data = []\n",
    "for d in data_:\n",
    "    new_d = {}\n",
    "    for k in keys:\n",
    "        if(isinstance(d[k.encode(\"utf-8\")],bytes)):\n",
    "            new_d[k]=d[k.encode(\"utf-8\")].decode(\"utf-8\")\n",
    "        else:\n",
    "            new_d[k]=d[k.encode(\"utf-8\")]\n",
    "    np_data.append(new_d)\n",
    "\n",
    "np.save(\"final_data.npy\",np.array(np_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_data.npy\",\"rb\") as file:\n",
    "    data = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hanlde_bool_and_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = all_data.link_flair_text\n",
    "X = all_data.drop('link_flair_text',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = [X_train.title]\n",
    "all_texts.extend(X_train.selftext)\n",
    "for comment in X_train.comments:\n",
    "    all_texts.extend(comment)\n",
    "all_texts = np.array(all_texts)\n",
    "for x in all_texts[0]:\n",
    "    all_texts[0] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastText_model = FastText(all_texts, min_count=1,size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fast_text_model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "joblib.dump(fastText_model, 'fast_text_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [u'edited', u'num_comments',u'num_duplicates',u'subreddit_subscribers', u'ups', u'upvote_ratio']\n",
    "numeric_X_train = X_train[numerical_cols]\n",
    "numeric_X_test = X_test[numerical_cols]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numeric_X_train_minmax = scaler.fit_transform(numeric_X_train)\n",
    "numeric_X_train_minmax = pd.DataFrame(numeric_X_train_minmax, index=numeric_X_train.index, columns=numeric_X_train.columns)\n",
    "numeric_X_train_minmax = numeric_X_train_minmax.loc[:, numeric_X_train_minmax.std() > 0]\n",
    "final_numeric_cols = numeric_X_train_minmax.columns\n",
    "\n",
    "joblib.dump(scaler, 'scaler.pkl') \n",
    "numeric_X_test_minmax = scaler.transform(numeric_X_test)\n",
    "numeric_X_test_minmax = pd.DataFrame(numeric_X_test_minmax, index=numeric_X_test.index, columns=numeric_X_test.columns)\n",
    "numeric_X_test_minmax = numeric_X_test_minmax[final_numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(numerical_cols,axis=1)\n",
    "X_test = X_test.drop(numerical_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = X_test.join(numeric_X_test_minmax)\n",
    "X_train_final = X_train.join(numeric_X_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_robot_indexable', 'no_follow', 'distinguished']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_same_val = []\n",
    "for col in X_train_final.columns:\n",
    "    if isinstance(X_train_final[col].iloc[0],np.number):\n",
    "        if X_train_final[col].nunique() == 1:\n",
    "            cols_with_same_val.append(col)\n",
    "    else:\n",
    "        if X_train_final[col].isnull().all():\n",
    "            cols_with_same_val.append(col)\n",
    "    i=0\n",
    "    flag = True\n",
    "    for x in X_train_final[col]:\n",
    "        if(x!=None and x!=[] and x!=\"\"):\n",
    "            flag = False\n",
    "            break\n",
    "    if flag == True and col not in cols_with_same_val:\n",
    "        cols_with_same_val.append(col)\n",
    "    \n",
    "cols_with_same_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train_final.drop(columns=cols_with_same_val)\n",
    "X_test_final = X_test_final.drop(columns=cols_with_same_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_FEATURES = X_train_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'selftext', 'secure_media', 'is_reddit_media_domain',\n",
       "       'comments', 'send_replies', 'over_18', 'permalink', 'url', 'title',\n",
       "       'is_original_content', 'is_video', 'edited', 'num_comments',\n",
       "       'num_duplicates', 'subreddit_subscribers', 'ups', 'upvote_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = X_train_final.join(y_train)\n",
    "testing_data = X_test_final.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = training_data.select_dtypes(include=[object]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "selftext\n",
      "secure_media\n",
      "comments\n",
      "permalink\n",
      "url\n",
      "title\n"
     ]
    }
   ],
   "source": [
    "temp_train = training_data\n",
    "for obj_col in obj_cols:\n",
    "    print(obj_col)\n",
    "    temp_train = get_obj_column(obj_col,temp_train,fastText_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "selftext\n",
      "secure_media\n",
      "comments\n",
      "permalink\n",
      "url\n",
      "title\n"
     ]
    }
   ],
   "source": [
    "temp_test = testing_data\n",
    "for obj_col in obj_cols:\n",
    "    print(obj_col)\n",
    "    temp_test = get_obj_column(obj_col,temp_test,fastText_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!!!\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    connection = MongoClient() \n",
    "    print(\"Connected successfully!!!\") \n",
    "except:   \n",
    "    print(\"Could not connect to MongoDB\")\n",
    "    \n",
    "database = connection.flair_database\n",
    "coll_train = database.training_data4\n",
    "coll_test = database.testing_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f3b2ae0d288>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_train.insert_many(temp_train.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f3b2a8ce2c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_test.insert_many(temp_test.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 19)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792, 19)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
