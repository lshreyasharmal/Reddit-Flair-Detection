{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/iiitd/.local/lib/python3.5/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/iiitd/.local/lib/python3.5/site-packages (from sklearn) (0.22)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/iiitd/.local/lib/python3.5/site-packages (from scikit-learn->sklearn) (1.3.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/iiitd/.local/lib/python3.5/site-packages (from scikit-learn->sklearn) (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/iiitd/.local/lib/python3.5/site-packages (from scikit-learn->sklearn) (1.16.1)\n",
      "Requirement already satisfied: gensim in /home/iiitd/.local/lib/python3.5/site-packages (3.8.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/iiitd/.local/lib/python3.5/site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/iiitd/.local/lib/python3.5/site-packages (from gensim) (1.3.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/iiitd/.local/lib/python3.5/site-packages (from gensim) (1.16.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/lib/python3/dist-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: boto>=2.32 in /home/iiitd/.local/lib/python3.5/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from smart-open>=1.8.1->gensim) (2.9.1)\n",
      "Requirement already satisfied: boto3 in /home/iiitd/.local/lib/python3.5/site-packages (from smart-open>=1.8.1->gensim) (1.10.34)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/iiitd/.local/lib/python3.5/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.34 in /home/iiitd/.local/lib/python3.5/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.13.34)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/iiitd/.local/lib/python3.5/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/iiitd/.local/lib/python3.5/site-packages (from botocore<1.14.0,>=1.13.34->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /home/iiitd/.local/lib/python3.5/site-packages (from botocore<1.14.0,>=1.13.34->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /home/iiitd/.local/lib/python3.5/site-packages (from botocore<1.14.0,>=1.13.34->boto3->smart-open>=1.8.1->gensim) (1.25.7)\n",
      "Requirement already satisfied: numpy==1.16.1 in /home/iiitd/.local/lib/python3.5/site-packages (1.16.1)\n",
      "Requirement already satisfied: bs4 in /home/iiitd/.local/lib/python3.5/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/iiitd/.local/lib/python3.5/site-packages (from bs4) (4.8.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /home/iiitd/.local/lib/python3.5/site-packages (from beautifulsoup4->bs4) (1.9.5)\n",
      "Requirement already satisfied: nltk in /home/iiitd/.local/lib/python3.5/site-packages (3.4.5)\n",
      "Requirement already satisfied: singledispatch in /home/iiitd/.local/lib/python3.5/site-packages (from nltk) (3.4.0.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from nltk) (1.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn --user\n",
    "!pip install gensim --user\n",
    "!pip install numpy==1.16.1 --user\n",
    "!pip install bs4 --user\n",
    "!pip install nltk --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/iiitd/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/iiitd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from pymongo import MongoClient \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from gensim.models import FastText\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# from preprocessing_functions import *\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"posts2.npy\",\"rb\") as file:\n",
    "    data = np.load(file,allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['num_comments',\n",
    "            'ups',\n",
    "            'is_reddit_media_domain',\n",
    "            'is_robot_indexable',\n",
    "            'is_video',\n",
    "            'no_follow',\n",
    "            'title',\n",
    "            'is_original_content',\n",
    "            'send_replies',\n",
    "            'permalink',\n",
    "            'edited',\n",
    "            'upvote_ratio',\n",
    "            'author',\n",
    "            'selftext',\n",
    "            'over_18',\n",
    "            'comments',\n",
    "            'subreddit_subscribers',\n",
    "            'secure_media',\n",
    "            'num_duplicates',\n",
    "            'url',\n",
    "            'distinguished',\n",
    "            'link_flair_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "i = 0\n",
    "for d in data:\n",
    "    post = vars(d)\n",
    "    cmts = []\n",
    "    d.comments.replace_more(limit=None)\n",
    "    for comment in d.comments.list():\n",
    "                cmts.append(comment.body)\n",
    "    post['comments'] = cmts\n",
    "    author = str(d.author).split(\"'\")\n",
    "    post['author'] = author[len(author)-2]\n",
    "    datapoint = {field:post[field] for field in features}\n",
    "    dataset.append(datapoint)\n",
    "    i+=1\n",
    "    if i==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>edited</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>is_reddit_media_domain</th>\n",
       "      <th>is_robot_indexable</th>\n",
       "      <th>is_video</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>...</th>\n",
       "      <th>over_18</th>\n",
       "      <th>permalink</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>selftext</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prtthrowaway</td>\n",
       "      <td>[I ll copy paste one of my previous comments-\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/india/comments/dacmel/askindia_my_brothers_...</td>\n",
       "      <td>None</td>\n",
       "      <td>My brother received bunch of SMS this morning ...</td>\n",
       "      <td>True</td>\n",
       "      <td>270015</td>\n",
       "      <td>[askindia] My brothers bank account was hacked...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.93</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/dacmel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sleepless_indian</td>\n",
       "      <td>[My mom says I'm good looking. Can I answer? \\...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/india/comments/cprtaa/attractive_men_what_t...</td>\n",
       "      <td>None</td>\n",
       "      <td>xposted from /r/askmen, posted here because In...</td>\n",
       "      <td>True</td>\n",
       "      <td>270015</td>\n",
       "      <td>Attractive men, what type of attention do you ...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.77</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/cprtaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hb4100</td>\n",
       "      <td>[Here’s the simple answer:-\\n\\n1. Echo is to d...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.56852e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/india/comments/d41pq6/why_do_indian_doctors...</td>\n",
       "      <td>None</td>\n",
       "      <td>Some context: (We're Indian in India), My pare...</td>\n",
       "      <td>True</td>\n",
       "      <td>270015</td>\n",
       "      <td>Why do Indian doctors have such a large ego?</td>\n",
       "      <td>117</td>\n",
       "      <td>0.80</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/d41pq6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prashantvc</td>\n",
       "      <td>[Never let a tenant stay even a minute beyond ...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.5658e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/india/comments/cq5tzw/askindia_help_me_deal...</td>\n",
       "      <td>None</td>\n",
       "      <td>Background: I rented my house to friend's acqu...</td>\n",
       "      <td>True</td>\n",
       "      <td>270015</td>\n",
       "      <td>[AskIndia] Help me deal with an asshole tenant</td>\n",
       "      <td>80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/cq5tzw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aashish2137</td>\n",
       "      <td>[NRI with a fairly neutral opinion here.\\n\\nSo...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[R]eddiquette</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/india/comments/c4ilk5/askindiaserious_is_it...</td>\n",
       "      <td>None</td>\n",
       "      <td>Title. \\n\\nFrom what I understand based on arm...</td>\n",
       "      <td>True</td>\n",
       "      <td>270015</td>\n",
       "      <td>[AskIndia][Serious] Is it worth attempting imm...</td>\n",
       "      <td>53</td>\n",
       "      <td>0.87</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/c4ilk5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                           comments  \\\n",
       "0      prtthrowaway  [I ll copy paste one of my previous comments-\\...   \n",
       "1  sleepless_indian  [My mom says I'm good looking. Can I answer? \\...   \n",
       "2            hb4100  [Here’s the simple answer:-\\n\\n1. Echo is to d...   \n",
       "3        prashantvc  [Never let a tenant stay even a minute beyond ...   \n",
       "4       aashish2137  [NRI with a fairly neutral opinion here.\\n\\nSo...   \n",
       "\n",
       "  distinguished       edited  is_original_content  is_reddit_media_domain  \\\n",
       "0          None        False                False                   False   \n",
       "1          None        False                False                   False   \n",
       "2          None  1.56852e+09                False                   False   \n",
       "3          None   1.5658e+09                False                   False   \n",
       "4          None        False                False                   False   \n",
       "\n",
       "   is_robot_indexable  is_video link_flair_text  no_follow  ...  over_18  \\\n",
       "0                True     False        AskIndia      False  ...    False   \n",
       "1                True     False   Non-Political      False  ...    False   \n",
       "2                True     False        AskIndia      False  ...    False   \n",
       "3                True     False        AskIndia      False  ...    False   \n",
       "4                True     False   [R]eddiquette      False  ...    False   \n",
       "\n",
       "                                           permalink  secure_media  \\\n",
       "0  /r/india/comments/dacmel/askindia_my_brothers_...          None   \n",
       "1  /r/india/comments/cprtaa/attractive_men_what_t...          None   \n",
       "2  /r/india/comments/d41pq6/why_do_indian_doctors...          None   \n",
       "3  /r/india/comments/cq5tzw/askindia_help_me_deal...          None   \n",
       "4  /r/india/comments/c4ilk5/askindiaserious_is_it...          None   \n",
       "\n",
       "                                            selftext send_replies  \\\n",
       "0  My brother received bunch of SMS this morning ...         True   \n",
       "1  xposted from /r/askmen, posted here because In...         True   \n",
       "2  Some context: (We're Indian in India), My pare...         True   \n",
       "3  Background: I rented my house to friend's acqu...         True   \n",
       "4  Title. \\n\\nFrom what I understand based on arm...         True   \n",
       "\n",
       "  subreddit_subscribers                                              title  \\\n",
       "0                270015  [askindia] My brothers bank account was hacked...   \n",
       "1                270015  Attractive men, what type of attention do you ...   \n",
       "2                270015       Why do Indian doctors have such a large ego?   \n",
       "3                270015     [AskIndia] Help me deal with an asshole tenant   \n",
       "4                270015  [AskIndia][Serious] Is it worth attempting imm...   \n",
       "\n",
       "   ups upvote_ratio                                                url  \n",
       "0   42         0.93  https://www.reddit.com/r/india/comments/dacmel...  \n",
       "1   20         0.77  https://www.reddit.com/r/india/comments/cprtaa...  \n",
       "2  117         0.80  https://www.reddit.com/r/india/comments/d41pq6...  \n",
       "3   80         0.94  https://www.reddit.com/r/india/comments/cq5tzw...  \n",
       "4   53         0.87  https://www.reddit.com/r/india/comments/c4ilk5...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe.to_csv(\"collected_data.csv\",header=True,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in dataframe.columns:\n",
    "#     if(dataframe[col].dtype == object):\n",
    "#         print(col, dataframe[col][0])\n",
    "#         dataframe.comments\n",
    "#         print()\n",
    "# for row in dataframe.rows:\n",
    "#     print(row)\n",
    "#     break\n",
    "\n",
    "# dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.comments.replace_more(limit=None)\n",
    "#         for comment in submission.comments.list():\n",
    "#                 comments.append(comment.body)\n",
    "#         post['comments'] = comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_original_content', 'permalink', 'ups', 'edited', 'title', 'is_reddit_media_domain', 'over_18', 'url', 'selftext', 'link_flair_text', 'num_comments', 'send_replies', 'num_duplicates', 'is_video', 'upvote_ratio', 'secure_media', 'is_robot_indexable', 'comments', 'author', 'distinguished', 'subreddit_subscribers', 'no_follow']\n"
     ]
    }
   ],
   "source": [
    "# with open(\"all_data.npy\",\"rb\") as file:\n",
    "#     data_ = np.load(file,encoding='bytes')\n",
    "\n",
    "keys = [x  for x in dataset[0].keys()]\n",
    "print(keys)\n",
    "\n",
    "np_data = []\n",
    "for d in dataset:\n",
    "    new_d = {}\n",
    "    for k in keys:\n",
    "        new_d[k]=d[k]\n",
    "    np_data.append(new_d)\n",
    "\n",
    "# np.save(\"final_data.npy\",np.array(np_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.reddit.com/r/india/comments/dacmel/askindia_my_brothers_bank_account_was_hacked_this/'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"final_data.npy\",\"rb\") as file:\n",
    "#     data = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def convert_boolean(value):\n",
    "    return (1 if value else 0)\n",
    "\n",
    "def tokenize_(sentence):\n",
    "    punctuations = set(string.punctuation)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    if(sentence==None):\n",
    "        return \"\"\n",
    "#     sentence = sentence.encode('ascii', 'ignore').decode('ascii')\n",
    "    sentence = sentence.replace(\"\\n\",\"\")\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'\\d+', '', sentence)\n",
    "    sentence = re.sub(r'[^\\w\\s]','',sentence)\n",
    "    sentence = ''.join(ch for ch in sentence if ch not in punctuations)\n",
    "    tokens_ = nltk.word_tokenize(sentence)\n",
    "    tokens = []\n",
    "    for token in tokens_:\n",
    "        if(\"http\" in token or \".com\" in token or \"www\" in token):\n",
    "            continue\n",
    "        tokens.append(token)\n",
    "    final_tokens = [w for w in tokens if not w in stop_words] \n",
    "    return final_tokens\n",
    "\n",
    "def tokenize_media(dict_obj):\n",
    "    if(dict_obj==None):\n",
    "        return \"\"\n",
    "    if \"oembed\" in dict_obj.keys():\n",
    "        if \"html\" in dict_obj['oembed'].keys():\n",
    "            html_text = BeautifulSoup(dict_obj['oembed']['html'], \"lxml\").text\n",
    "        else:\n",
    "            return tokenize_(\"\")\n",
    "    else:\n",
    "        return tokenize_(\"\")\n",
    "    return tokenize_(html_text)\n",
    "\n",
    "def tokenize_urls(link):\n",
    "    print(link)\n",
    "    link = re.sub(r'^r/', ' ', link)\n",
    "    link = re.sub(r'/', ' ', link)\n",
    "    link = re.sub(r'_', ' ', link)\n",
    "    link = re.sub(r'https','',link)\n",
    "    link = re.sub(r'www','',link)\n",
    "    link = re.sub(r'.com','',link)\n",
    "    return tokenize_(link)\n",
    "\n",
    "def buildWordVector(tokens,model):\n",
    "    size=10\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model.wv[word].reshape((1, size))\n",
    "        except:\n",
    "            vec += np.zeros(size).reshape((1, size))\n",
    "        count += 1.\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "\n",
    "def get_avg_comment_vec(comments,model):\n",
    "    size = 10\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for comment in comments:\n",
    "        vec += buildWordVector(comment,model)\n",
    "        count += 1.\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "\n",
    "def get_obj_column(col,df,model):\n",
    "    if col == \"comments\":\n",
    "        temp = [get_avg_comment_vec(x,model) for x in df[col]]\n",
    "    else:\n",
    "        temp = [buildWordVector(x,model) for x in df[col]]\n",
    "    temp_ = [list(np.ravel(x)) for x in temp]\n",
    "    temp_df = pd.DataFrame([temp_])\n",
    "    temp_df_t = temp_df.transpose()\n",
    "    temp_df_t.columns = [col]\n",
    "    temp_df_t.index = df.index\n",
    "    df = df.drop(columns = [col])\n",
    "    df = df.join(temp_df_t)\n",
    "    return df\n",
    "\n",
    "def hanlde_bool_and_tokenize(data2):\n",
    "    for line in data2:\n",
    "        for k,v in line.items():\n",
    "#             print(k,v)\n",
    "            print(k,type(v))\n",
    "#             if isinstance(v,bool):\n",
    "#                 line[k] = convert_boolean(v)\n",
    "#             if(k==\"secure_media\"):\n",
    "#                 line[k] = tokenize_media(v)\n",
    "#             if(k==\"author\"):\n",
    "#                 line[k] = tokenize_(v)\n",
    "#             if(k==\"comments\"):\n",
    "#                 converted_comments = []\n",
    "#                 for comment in v:\n",
    "#                     converted_comments.append(tokenize_(comment))\n",
    "#                 line[k] = converted_comments\n",
    "# #             if(k==\"permalink\"):\n",
    "# #                 line[k] = tokenize_urls(v)\n",
    "# #             if(k==\"url\"):\n",
    "# #                 line[k] = tokenize_urls(v)\n",
    "#             if(k==\"selftext\"):\n",
    "#                 line[k] = tokenize_(v)\n",
    "#             if(k==\"title\"):\n",
    "#                 line[k] = tokenize_(v)\n",
    "#     return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prtthrowaway\n",
      "is_original_content <class 'bool'>\n",
      "permalink <class 'str'>\n",
      "ups <class 'int'>\n",
      "distinguished <class 'NoneType'>\n",
      "title <class 'str'>\n",
      "is_reddit_media_domain <class 'bool'>\n",
      "over_18 <class 'bool'>\n",
      "url <class 'str'>\n",
      "is_video <class 'bool'>\n",
      "link_flair_text <class 'str'>\n",
      "num_comments <class 'int'>\n",
      "send_replies <class 'bool'>\n",
      "num_duplicates <class 'int'>\n",
      "selftext <class 'str'>\n",
      "upvote_ratio <class 'float'>\n",
      "secure_media <class 'NoneType'>\n",
      "is_robot_indexable <class 'bool'>\n",
      "comments <class 'list'>\n",
      "author <class 'str'>\n",
      "edited <class 'bool'>\n",
      "subreddit_subscribers <class 'int'>\n",
      "no_follow <class 'bool'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'dataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e61406fc9e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'dataFrame'"
     ]
    }
   ],
   "source": [
    "for d in np_data:\n",
    "    print(d['author'])\n",
    "    for k,v in d.items():\n",
    "        print(k,type(v))\n",
    "    break\n",
    "pd.dataFrame.from_record(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = all_data.link_flair_text\n",
    "# X = all_data.drop('link_flair_text',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_texts = [X_train.title]\n",
    "# all_texts.extend(X_train.selftext)\n",
    "# for comment in X_train.comments:\n",
    "#     all_texts.extend(comment)\n",
    "# all_texts = np.array(all_texts)\n",
    "# for x in all_texts[0]:\n",
    "#     all_texts[0] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastText_model = FastText(all_texts, min_count=1,size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fast_text_model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib \n",
    "# joblib.dump(fastText_model, 'fast_text_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [u'edited', u'num_comments',u'num_duplicates',u'subreddit_subscribers', u'ups', u'upvote_ratio']\n",
    "numeric_X_train = X_train[numerical_cols]\n",
    "numeric_X_test = X_test[numerical_cols]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numeric_X_train_minmax = scaler.fit_transform(numeric_X_train)\n",
    "numeric_X_train_minmax = pd.DataFrame(numeric_X_train_minmax, index=numeric_X_train.index, columns=numeric_X_train.columns)\n",
    "numeric_X_train_minmax = numeric_X_train_minmax.loc[:, numeric_X_train_minmax.std() > 0]\n",
    "final_numeric_cols = numeric_X_train_minmax.columns\n",
    "\n",
    "joblib.dump(scaler, 'scaler.pkl') \n",
    "numeric_X_test_minmax = scaler.transform(numeric_X_test)\n",
    "numeric_X_test_minmax = pd.DataFrame(numeric_X_test_minmax, index=numeric_X_test.index, columns=numeric_X_test.columns)\n",
    "numeric_X_test_minmax = numeric_X_test_minmax[final_numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(numerical_cols,axis=1)\n",
    "X_test = X_test.drop(numerical_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = X_test.join(numeric_X_test_minmax)\n",
    "X_train_final = X_train.join(numeric_X_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_robot_indexable', 'no_follow', 'distinguished']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_same_val = []\n",
    "for col in X_train_final.columns:\n",
    "    if isinstance(X_train_final[col].iloc[0],np.number):\n",
    "        if X_train_final[col].nunique() == 1:\n",
    "            cols_with_same_val.append(col)\n",
    "    else:\n",
    "        if X_train_final[col].isnull().all():\n",
    "            cols_with_same_val.append(col)\n",
    "    i=0\n",
    "    flag = True\n",
    "    for x in X_train_final[col]:\n",
    "        if(x!=None and x!=[] and x!=\"\"):\n",
    "            flag = False\n",
    "            break\n",
    "    if flag == True and col not in cols_with_same_val:\n",
    "        cols_with_same_val.append(col)\n",
    "    \n",
    "cols_with_same_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train_final.drop(columns=cols_with_same_val)\n",
    "X_test_final = X_test_final.drop(columns=cols_with_same_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_FEATURES = X_train_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'selftext', 'secure_media', 'is_reddit_media_domain',\n",
       "       'comments', 'send_replies', 'over_18', 'permalink', 'url', 'title',\n",
       "       'is_original_content', 'is_video', 'edited', 'num_comments',\n",
       "       'num_duplicates', 'subreddit_subscribers', 'ups', 'upvote_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = X_train_final.join(y_train)\n",
    "testing_data = X_test_final.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = training_data.select_dtypes(include=[object]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "selftext\n",
      "secure_media\n",
      "comments\n",
      "permalink\n",
      "url\n",
      "title\n"
     ]
    }
   ],
   "source": [
    "temp_train = training_data\n",
    "for obj_col in obj_cols:\n",
    "    print(obj_col)\n",
    "    temp_train = get_obj_column(obj_col,temp_train,fastText_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "selftext\n",
      "secure_media\n",
      "comments\n",
      "permalink\n",
      "url\n",
      "title\n"
     ]
    }
   ],
   "source": [
    "temp_test = testing_data\n",
    "for obj_col in obj_cols:\n",
    "    print(obj_col)\n",
    "    temp_test = get_obj_column(obj_col,temp_test,fastText_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!!!\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    connection = MongoClient() \n",
    "    print(\"Connected successfully!!!\") \n",
    "except:   \n",
    "    print(\"Could not connect to MongoDB\")\n",
    "    \n",
    "database = connection.flair_database\n",
    "coll_train = database.training_data4\n",
    "coll_test = database.testing_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f3b2ae0d288>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_train.insert_many(temp_train.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f3b2a8ce2c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_test.insert_many(temp_test.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 19)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792, 19)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
